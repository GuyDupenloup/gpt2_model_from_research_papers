
>>>> Trainable variables in smallest model

gpt2_model/token_embd/embeddings:0:   (50257, 768) = 38597376
gpt2_model/position_embd/embeddings:0:   (1024, 768) = 786432
gpt2_model/transformer_0/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_0/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_0/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_0/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_0/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_0/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_0/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_0/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_0/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_0/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_0/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_0/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_1/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_1/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_1/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_1/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_1/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_1/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_1/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_1/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_1/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_1/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_1/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_1/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_2/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_2/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_2/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_2/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_2/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_2/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_2/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_2/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_2/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_2/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_2/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_2/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_3/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_3/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_3/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_3/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_3/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_3/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_3/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_3/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_3/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_3/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_3/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_3/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_4/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_4/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_4/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_4/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_4/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_4/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_4/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_4/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_4/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_4/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_4/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_4/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_5/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_5/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_5/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_5/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_5/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_5/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_5/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_5/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_5/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_5/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_5/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_5/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_6/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_6/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_6/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_6/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_6/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_6/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_6/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_6/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_6/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_6/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_6/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_6/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_7/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_7/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_7/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_7/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_7/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_7/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_7/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_7/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_7/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_7/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_7/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_7/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_8/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_8/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_8/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_8/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_8/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_8/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_8/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_8/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_8/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_8/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_8/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_8/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_9/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_9/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_9/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_9/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_9/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_9/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_9/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_9/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_9/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_9/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_9/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_9/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_10/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_10/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_10/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_10/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_10/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_10/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_10/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_10/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_10/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_10/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_10/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_10/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/transformer_11/lnorm_1/gamma:0:   (768,) = 768
gpt2_model/transformer_11/lnorm_1/beta:0:   (768,) = 768
gpt2_model/transformer_11/attention/W_qkv/kernel:0:   (768, 2304) = 1769472
gpt2_model/transformer_11/attention/W_qkv/bias:0:   (2304,) = 2304
gpt2_model/transformer_11/attention/c_proj/kernel:0:   (768, 768) = 589824
gpt2_model/transformer_11/attention/c_proj/bias:0:   (768,) = 768
gpt2_model/transformer_11/lnorm_2/gamma:0:   (768,) = 768
gpt2_model/transformer_11/lnorm_2/beta:0:   (768,) = 768
gpt2_model/transformer_11/ffn/ffn_inner/kernel:0:   (768, 3072) = 2359296
gpt2_model/transformer_11/ffn/ffn_inner/bias:0:   (3072,) = 3072
gpt2_model/transformer_11/ffn/ffn_out/kernel:0:   (3072, 768) = 2359296
gpt2_model/transformer_11/ffn/ffn_out/bias:0:   (768,) = 768
gpt2_model/lnorm_f/gamma:0:   (768,) = 768
gpt2_model/lnorm_f/beta:0:   (768,) = 768

Total trainable parameters: 124439808
